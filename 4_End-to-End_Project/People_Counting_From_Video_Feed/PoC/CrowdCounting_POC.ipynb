{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting Crowds with DL\n",
    "## Proof Of Concept\n",
    "The notebook will implement [Dense Scale Networks](https://arxiv.org/pdf/1906.09707.pdf) for the purpose of counting crowds for images.\n",
    "The dataset will be the same as the one, detailed in the paper - the ShangaiTech."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and loading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import scipy.io\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import mse, mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Getting Data to Train the model.\n",
    "A couple of datasets are available to use for the purpose of training. My goal is to try to combine them all and train the dense scale network on all of them and evaluate them on all tests set.\n",
    "\n",
    "*NOTE*: Provide List of more famous Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 UCF-QNRF_ECCV18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### --- Exploring the data format and images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TODO:* Learn images original size and aspect ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'annPoints'])\n",
      "(433, 2)\n"
     ]
    }
   ],
   "source": [
    "ucf_qnrf_example = scipy.io.loadmat('training_dataset/UCF-QNRF_ECCV18/Train/img_0001_ann.mat')\n",
    "print(ucf_qnrf_example.keys())\n",
    "print(ucf_qnrf_example['annPoints'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Judging from the keys of the example it seems, that the .mat files contain the annotation points. Since my gould is counting the people and not where they are I will take only the count of the annotations and not their respective coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_vector(dataset_path):\n",
    "    '''\n",
    "        Gets the density/count vector by reading the .mat file \n",
    "        and getting the shape of the file. \n",
    "        The function only requires the path to the dataset.\n",
    "    '''\n",
    "    file_contents = os.listdir(dataset_path)\n",
    "    only_mat_files = list(filter(lambda x: '.mat' in x, file_contents))\n",
    "    \n",
    "    densities = {'image_name':[], 'count': []}\n",
    "    for mat in only_mat_files:\n",
    "        filepath = os.path.join(dataset_path, mat)\n",
    "        mat_loaded = scipy.io.loadmat(filepath)\n",
    "        # we attach the .jpg at the end for the respective image\n",
    "        densities['image_name'].append(mat.split('.mat')[0] + '.jpg')\n",
    "        densities['count'].append(mat_loaded['annPoints'].shape[0])      \n",
    "    \n",
    "    # return it as a pandas dataframe\n",
    "    return pd.DataFrame(densities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = get_count_vector('training_dataset/UCF-QNRF_ECCV18/Train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_0683_ann.jpg</td>\n",
       "      <td>928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_0648_ann.jpg</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_0560_ann.jpg</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_0002_ann.jpg</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_0295_ann.jpg</td>\n",
       "      <td>697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_name  count\n",
       "0  img_0683_ann.jpg    928\n",
       "1  img_0648_ann.jpg    260\n",
       "2  img_0560_ann.jpg    108\n",
       "3  img_0002_ann.jpg    121\n",
       "4  img_0295_ann.jpg    697"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -- Keras DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 validated image filenames.\n",
      "Found 0 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fury/anaconda3/lib/python3.7/site-packages/keras_preprocessing/image/dataframe_iterator.py:273: UserWarning: Found 1201 invalid image filename(s) in x_col=\"image_name\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255., validation_split=0.1) # we dont have much data as it is\n",
    "train_iter = train_datagen.flow_from_dataframe(dataframe=train_df,\n",
    "                                               directory='training_dataset/UCF-QNRF_ECCV18/Train/',\n",
    "                                               x_col='image_name',\n",
    "                                               y_col='count',\n",
    "                                               subset='training',\n",
    "                                               target_size=(224, 224),\n",
    "                                               class_mode='raw')\n",
    "\n",
    "valid_iter = train_datagen.flow_from_dataframe(dataframe=train_df,\n",
    "                                               directory='training_dataset/UCF-QNRF_ECCV18/Train/',\n",
    "                                               x_col='image_name',\n",
    "                                               y_col='count',\n",
    "                                               subset='validation',\n",
    "                                               target_size=(224, 224),\n",
    "                                               class_mode='raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-61b1648276c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "# Show one of the images\n",
    "x, y = train_iter.next()\n",
    "for i in range(0,1):\n",
    "    print(y[i])\n",
    "    image = x[i]\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building the Model\n",
    "In order to build ithe Deep scale network first the Dense Dialated Convolution Block has to be implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(keras.models.Model):\n",
    "    '''\n",
    "        TODO: Add Docstring\n",
    "    '''\n",
    "    def __init__(self, activation='relu', padding=1, dilation_rate=1, **kwargs):\n",
    "        super.__init__(**kwargs)\n",
    "        self.conv1 = keras.layers.Conv2D(256, (1, 1), activation=activation)\n",
    "        self.padding = keras.layers.ZeroPadding2D(padding=(padding, padding))\n",
    "        self.conv2 = keras.layers.Conv2D(64, (3, 3), padding='valid', dilation_rate=dilation_rate, activation=activation)\n",
    "    def call(self, inputs):\n",
    "        out = self.conv1(inputs)\n",
    "        out = self.padding(out)\n",
    "        out = self.conv2(out)\n",
    "        \n",
    "        return out    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDCB(keras.models.Model):\n",
    "    '''\n",
    "        TODO: Add Docstring\n",
    "    '''\n",
    "    def __init__(self, activation='relu', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.convBlock1 = ConvBlock()\n",
    "        self.convBlock2 = ConvBlock(padding=2, dilation_rate=2)\n",
    "        self.convBlock3 = ConvBlock(padding=3, dilation_rate=3)\n",
    "        self.paddingOut = keras.layers.ZeroPadding2D(padding=(1,1))\n",
    "        self.convOut = keras.layers.Conv2D(512, (3, 3), padding='valid', activation='relu')\n",
    "    \n",
    "    def call(inputs):\n",
    "        out1 = self.convBlock1(inputs)\n",
    "        out2 = keras.layers.Concatenate([inputs, out1])\n",
    "        out3 = self.convBlock2(out2)\n",
    "        out4 = keras.layers.Concatenate([inputs, out1, out3])\n",
    "        out5 = self.convBlock3(out4)\n",
    "        out6 = keras.layers.Concatenate([inputs, out3, out5])\n",
    "        out7 = self.paddingOut(out6)\n",
    "        out8 = self.convOut(out7)\n",
    "        return out8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseScaleNet(keras.models.Model):\n",
    "    '''\n",
    "        TODO: Add Docstring\n",
    "    '''\n",
    "    def __init__(self, model=None, input_shape=None):\n",
    "        super().__init__(**kwargs)\n",
    "        if model is None:\n",
    "            if input_shape is None:\n",
    "                raise Exception('A model could not have an input shape set to None.')\n",
    "                \n",
    "            model = self.__create_backbone(input_shape)\n",
    "        \n",
    "        self.model = model\n",
    "        self.DDCB1 = DDCB()\n",
    "        self.DDCB2 = DDCB()\n",
    "        self.DDCB3 = DDCB()\n",
    "        self.padding1 = keras.layers.ZeroPadding2D(padding=(1,1))\n",
    "        self.conv1 = keras.layers.Conv2D(128, (3, 3), padding='valid', activation='relu')\n",
    "        self.padding2 = keras.layers.ZeroPadding2D(padding=(1,1))\n",
    "        self.conv2 = keras.layers.Conv2D(64, (3,3), padding='valid', activation='relu')\n",
    "        self.outconv = keras.layers.Conv2D(1, (1, 1), activation='relu')\n",
    "    \n",
    "    def __create_backbone(self, input_shape):\n",
    "        '''\n",
    "            TODO: Add Doctstring\n",
    "        '''\n",
    "        vgg16_model = keras.applications.vgg16.VGG16(weights='imagenet', input_shape=input_shape)\n",
    "        model = keras.models.Sequential()\n",
    "        \n",
    "        # we want to copy the first ten layers from VGG16\n",
    "        for layer in vgg16_model[:11]:\n",
    "            model.add(layer)\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        out1 = self.model(inputs)\n",
    "        out2 = self.DDCB1(out1)\n",
    "        out3 = out2 + out3\n",
    "        out4 = self.DDCB2(out3)\n",
    "        out5 = out4 + out2 + out1\n",
    "        out6 = self.DDCB3(out5)\n",
    "        out7 = out6 + out4 + out2 + out1\n",
    "        out = self.padding1(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.padding2(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.outconv(out)\n",
    "        \n",
    "        return out           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

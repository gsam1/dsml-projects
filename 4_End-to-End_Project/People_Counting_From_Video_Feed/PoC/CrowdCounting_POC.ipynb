{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting Crowds with Deep Learning\n",
    "## Proof Of Concept\n",
    "\n",
    "The notebook will implement various papers for the puprose of crowd counting\n",
    "* [Dense Scale Networks](https://arxiv.org/pdf/1906.09707.pdf)\n",
    "* [CSRNet: Dilated Convolutional Neural Networks](https://arxiv.org/pdf/1802.10062.pdf)\n",
    "\n",
    "The goal - to find the best approach to teach a model to count crowds, based on input images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from skimage import exposure, img_as_float\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reporting module\n",
    "from ovreport.report import report_to_overwatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Globals\n",
    "A number of parameters on top of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Paths\n",
    "train_path_UCF_QNRF = 'training_dataset/UCF-QNRF_ECCV18/Train_h5/'\n",
    "test_path_UCF_QNRF = 'training_dataset/UCF-QNRF_ECCV18/Test_h5/'\n",
    "# TODO: Add More ... add more\n",
    "\n",
    "# Target Image Size\n",
    "TARGET_SHAPE = (720, 480)\n",
    "\n",
    "\n",
    "MODEL_SAVE_PATH = 'models/best/DenseScaleNet_ucf_qnrf_aug_5e-6.pth'\n",
    "# Training Details\n",
    "TRAIN_BATCH_SIZE = 1\n",
    "TEST_BATCH_SIZE = 1\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 5e-6\n",
    "WEIGHT_DECAY = 5e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Dealing with Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawDataset(Dataset):\n",
    "    def __init__(self, root, transform, ratio=8, output_shape=False, aug=False):\n",
    "        self.nsamples = len(root)\n",
    "        self.aug = aug\n",
    "        self.output_shape = output_shape\n",
    "        self.root = root\n",
    "        self.ratio = ratio\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __augment(image, target, count, seed):\n",
    "        random.seed(seed)\n",
    "        \n",
    "        # apply random crop\n",
    "        if random.random() < 0.5:\n",
    "            crop_size = (img.size[0]//2, img.size[1]//2)\n",
    "        \n",
    "            if random.random() <=0.44:\n",
    "                # 4 non-overlapping patches\n",
    "                dx = int(random.randint(0,1) * crop_size[0])\n",
    "                dy = int(random.randint(0,1) * crop_size[1])\n",
    "            else:\n",
    "                # 5 random patches\n",
    "                # set seed to ensure for each image the random patches are certain\n",
    "                # if not set, the crop will be online which means the patches change every time loading, leading to a dynamic training set.\n",
    "                patch_id = random.randint(0, 4)\n",
    "                random.seed(index + patch_id * 0.1)\n",
    "                dx = int(random.random() * crop_size[0])\n",
    "                random.seed(index + 0.5 + patch_id * 0.1)\n",
    "                dy = int(random.random() * crop_size[1])\n",
    "            # crop\n",
    "            img = img.crop((dx, dy, crop_size[0]+dx, crop_size[1]+dy))\n",
    "            target = target[dy:crop_size[1]+dy, dx:crop_size[0]+dx]\n",
    "            count = float(target.sum())\n",
    "        \n",
    "        if random.random() > 0.5:\n",
    "            target = np.fliplr(target)\n",
    "            image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        \n",
    "        if random.random() > 0.7:\n",
    "            img = img_as_float(image)\n",
    "            # gamma_img: np.array(dtype=float64) ranging [0,1]\n",
    "            if random.random() > 0.5:\n",
    "                gamma_img = exposure.adjust_gamma(img, 1.5)\n",
    "            else:\n",
    "                gamma_img = exposure.adjust_gamma(img, 0.5)\n",
    "            gamma_img = gamma_img * 255\n",
    "            gamma_img = np.uint8(gamma_img)\n",
    "            image = Image.fromarray(gamma_img)\n",
    "        \n",
    "        return image, target, count\n",
    "    \n",
    "    def __resize_to_target(self, img, target_shape):\n",
    "        return cv2.resize(img, target_shape, interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    def __load_data(self, path, ratio=8, output_shape=None, aug=False, index=None):\n",
    "        src_h5 = h5py.File(path, 'r')\n",
    "        img = src_h5['image_array'].value\n",
    "        output = src_h5['density_map'].value\n",
    "        count = float(src_h5['count'].value)\n",
    "\n",
    "\n",
    "        if len(img.shape) < 3:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "        if output_shape is not None:\n",
    "            img = self.__resize_to_target(img, output_shape)\n",
    "            output = self.__resize_to_target(output, output_shape)\n",
    "\n",
    "        if aug:\n",
    "            # TODO: Implement augumentation\n",
    "            img, output, count = self.__augment(img, output, count, 42)\n",
    "\n",
    "        if ratio>1:\n",
    "            output = cv2.resize(output, \n",
    "                                (int(output.shape[1]/ratio),int(output.shape[0]/ratio)), \n",
    "                                interpolation=cv2.INTER_CUBIC) * (ratio**2)\n",
    "\n",
    "        output = np.reshape(output, (1, ) + output.shape)\n",
    "\n",
    "        return img, output, count        \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img, target, count = self.__load_data(self.root[index], output_shape=self.output_shape, aug=self.aug)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, target, count\n",
    "    def __len__(self):\n",
    "        return self.nsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(train_path, test_path, output_shape, ratio=8):\n",
    "    train_img_paths = glob.glob(os.path.join(train_path, '*.h5'))\n",
    "    test_img_paths = glob.glob(os.path.join(test_path, '*.h5'))\n",
    "    \n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "    train_dataset = RawDataset(train_img_paths, transform, ratio=ratio, output_shape=output_shape, aug=True)\n",
    "    test_dataset = RawDataset(test_img_paths, transform, ratio=1, output_shape=output_shape, aug=True)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=TRAIN_BATCH_SIZE)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, shuffle=False, batch_size=TEST_BATCH_SIZE)\n",
    "    \n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = get_loaders(train_path_UCF_QNRF, test_path_UCF_QNRF, output_shape=TARGET_SHAPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dense Scale Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDCB(nn.Module):\n",
    "    '''\n",
    "        TODO: Docstring\n",
    "    '''\n",
    "    def __init__(self, in_planes):\n",
    "        super(DDCB, self).__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(in_planes, 256, 1), nn.ReLU(True), nn.Conv2d(256, 64, 3, padding=1), nn.ReLU(True))\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(in_planes+64, 256, 1), nn.ReLU(True), nn.Conv2d(256, 64, 3, padding=2, dilation=2), nn.ReLU(True))\n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(in_planes+128, 256, 1), nn.ReLU(True), nn.Conv2d(256, 64, 3, padding=3, dilation=3), nn.ReLU(True))\n",
    "        self.conv4 = nn.Sequential(nn.Conv2d(in_planes+128, 512, 3, padding=1), nn.ReLU(True))\n",
    "    def forward(self, x):\n",
    "        x1_raw = self.conv1(x)\n",
    "        x1 = torch.cat([x, x1_raw], 1)\n",
    "        x2_raw = self.conv2(x1)\n",
    "        x2 = torch.cat([x, x1_raw, x2_raw], 1)\n",
    "        x3_raw = self.conv3(x2)\n",
    "        x3 = torch.cat([x, x2_raw, x3_raw], 1)\n",
    "        output = self.conv4(x3)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseScaleNet(nn.Module):\n",
    "    '''\n",
    "        TODO: Docstring\n",
    "    '''\n",
    "    def __init__(self, load_model='', pretrained_backbone=False, trainable_backbone=False):\n",
    "        super(DenseScaleNet, self).__init__()\n",
    "        self.load_model = load_model\n",
    "        self.pretrained_backbone = pretrained_backbone\n",
    "        self.trainable_backbone = trainable_backbone\n",
    "        # network\n",
    "        self.features = self.__get_backbone()\n",
    "        self.DDCB1 = DDCB(512)\n",
    "        self.DDCB2 = DDCB(512)\n",
    "        self.DDCB3 = DDCB(512)\n",
    "        self.output_layers = nn.Sequential(nn.Conv2d(512, 128, 3, padding=1), \n",
    "                                           nn.ReLU(True), \n",
    "                                           nn.Conv2d(128, 64, 3, padding=1), \n",
    "                                           nn.ReLU(True), \n",
    "                                           nn.Conv2d(64, 1, 1))\n",
    "#         self.__initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x1_raw = self.DDCB1(x)\n",
    "        x1 = x1_raw + x\n",
    "        x2_raw = self.DDCB2(x1)\n",
    "        x2 = x2_raw + x1_raw + x\n",
    "        x3_raw = self.DDCB3(x2)\n",
    "        x3 = x3_raw + x2_raw + x1_raw + x\n",
    "        output = self.output_layers(x3)\n",
    "        return output\n",
    "    \n",
    "    def __get_backbone(self):\n",
    "        if self.pretrained_backbone:\n",
    "            vgg16 = torchvision.models.vgg16(pretrained=True)\n",
    "            # only get the leayers we are interested in\n",
    "            backbone = vgg16.features[:23] # to match the layers in the paper\n",
    "            # make them untrainable if desired\n",
    "            if not self.trainable_backbone:\n",
    "                for param in backbone.parameters():\n",
    "                    param.requires_grad = False\n",
    "\n",
    "            return features = backbone\n",
    "        else:\n",
    "            self.features_cfg = [64, 64, 'M', \n",
    "                                 128, 128, 'M', \n",
    "                                 256, 256, 256, 'M', \n",
    "                                 512, 512, 512,]\n",
    "            return self.__make_layers(self.features_cfg)\n",
    "    \n",
    "    def __make_layers(self, cfg, in_channels=3, batch_norm=False, dilation=False):\n",
    "        if dilation:\n",
    "            d_rate = 2\n",
    "        else:\n",
    "            d_rate = 1\n",
    "        layers = []\n",
    "        for v in cfg:\n",
    "            if v == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=d_rate, dilation=d_rate)\n",
    "                if batch_norm:\n",
    "                    layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "                else:\n",
    "                    layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "                in_channels = v\n",
    "        return nn.Sequential(*layers)   \n",
    "    \n",
    "    def __initialize_weights(self):\n",
    "        self_dict = self.state_dict()\n",
    "        pretrained_dict = dict()\n",
    "        self.__random_initialize_weights()\n",
    "        if not self.load_model:\n",
    "            vgg16 = torchvision.models.vgg16(pretrained=True)\n",
    "            for k, v in vgg16.items():\n",
    "                if k in self_dict and self_dict[k].size() == v.size():\n",
    "                    pretrained_dict[k] = v\n",
    "            self_dict.update(pretrained_dict)\n",
    "            self.load_state_dict(self_dict)\n",
    "        else:\n",
    "            self.load_state_dict(torch.load(self.load_model))\n",
    "            \n",
    "    def __random_initialize_weights(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                nn.init.normal_(module.weight, std=0.01)\n",
    "                #nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if module.bias is not None:\n",
    "                    nn.init.constant_(module.bias, 0)\n",
    "            elif isinstance(module, nn.BatchNorm2d):\n",
    "                nn.init.constant_(module.weight, 1)\n",
    "                nn.init.constant_(module.bias, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Criterion, Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_lc_loss(output, target, sizes=(1,2,4)):\n",
    "    criterion_L1 = nn.L1Loss()\n",
    "    Lc_loss = None\n",
    "    for s in sizes:\n",
    "        pool = nn.AdaptiveAvgPool2d(s)\n",
    "        est = pool(output)\n",
    "        gt = pool(target)\n",
    "        if Lc_loss:\n",
    "            Lc_loss += criterion_L1(est, gt)\n",
    "        else:\n",
    "            Lc_loss = criterion_L1(est, gt)\n",
    "    return Lc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(output, target):\n",
    "    Le_Loss = criterion(output, target)\n",
    "    Lc_Loss = cal_lc_loss(output, target)\n",
    "    loss = Le_Loss + 1000 * Lc_Loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(model, test_loader):\n",
    "    model.eval()\n",
    "    mae = 0.0\n",
    "    mse = 0.0\n",
    "    with torch.no_grad():\n",
    "        for img, target, count in test_loader:\n",
    "            img = img.cuda()\n",
    "            output = model(img)\n",
    "            est_count = output.sum().item()\n",
    "            mae += abs(est_count - count)\n",
    "            mse += (est_count - count)**2\n",
    "    mae /= len(test_loader)\n",
    "    mse /= len(test_loader)\n",
    "    mse = mse**0.5\n",
    "    return float(mae), float(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -- Init Model\n",
    "Or load a pretrained one if exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(new=True):\n",
    "    '''\n",
    "        Initializes the Model.\n",
    "        If new is true it starts with a new model, else loads the one in the Model Save Path.\n",
    "    '''\n",
    "    if new:\n",
    "        dsn_net = DenseScaleNet('', pretrained_backbone=True)\n",
    "    elif os.path.exists(MODEL_SAVE_PATH):\n",
    "        dsn_net = DenseScaleNet('')\n",
    "        dsn_net.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "    else:\n",
    "        dsn_net = DenseScaleNet('')\n",
    "    \n",
    "    return dsn_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseScaleNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "  )\n",
       "  (DDCB1): DDCB(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv2d(576, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (0): Conv2d(640, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv4): Sequential(\n",
       "      (0): Conv2d(640, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (DDCB2): DDCB(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv2d(576, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (0): Conv2d(640, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv4): Sequential(\n",
       "      (0): Conv2d(640, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (DDCB3): DDCB(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv2d(576, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (0): Conv2d(640, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv4): Sequential(\n",
       "      (0): Conv2d(640, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (output_layers): Sequential(\n",
       "    (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsn_net = init_model(new=False)\n",
    "dsn_net.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(dsn_net.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, optimizer, model_save_path):\n",
    "    '''\n",
    "        TODO: Docstring\n",
    "    '''\n",
    "    best_mae, _  = val(model, test_loader)\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss = 0.0\n",
    "        model.train()\n",
    "        for img, target, count in tqdm(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            img = img.cuda()\n",
    "            target = target.float()\n",
    "            target = target.cuda()\n",
    "            output = model(img)\n",
    "\n",
    "            loss = calc_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        mae, mse = val(model, test_loader)\n",
    "\n",
    "        print('Epoch {}/{} Loss:{:.3f}, MAE:{:.2f}, MSE:{:.2f}, Best MAE:{:.2f}'.format(epoch+1, \n",
    "                                                                                        EPOCHS, \n",
    "                                                                                        train_loss/len(train_loader), \n",
    "                                                                                        mae, \n",
    "                                                                                        mse, \n",
    "                                                                                        best_mae))\n",
    "        if mae < best_mae:\n",
    "            best_mae = mae\n",
    "            print(f'New best mae: {best_mae}. Saving model!')\n",
    "            # report best model\n",
    "            report_to_overwatch('VM:ML:P', 'Atlas', f'Epoch {epoch} recorded a{best_mae}!')\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:33<00:00,  1.73it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 Loss:59.800, MAE:665.88, MSE:987.44, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:36<00:00,  1.72it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 Loss:56.523, MAE:624.96, MSE:931.34, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:35<00:00,  1.72it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 Loss:53.412, MAE:582.57, MSE:890.79, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:34<00:00,  1.73it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 Loss:49.422, MAE:612.13, MSE:911.75, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:35<00:00,  1.73it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 Loss:46.720, MAE:638.14, MSE:954.79, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:36<00:00,  1.72it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 Loss:44.399, MAE:653.13, MSE:955.56, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:37<00:00,  1.72it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 Loss:43.900, MAE:618.40, MSE:948.64, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:34<00:00,  1.73it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 Loss:41.904, MAE:621.24, MSE:936.46, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:33<00:00,  1.73it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 Loss:41.098, MAE:593.38, MSE:914.15, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:33<00:00,  1.73it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 Loss:39.859, MAE:676.48, MSE:984.95, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:34<00:00,  1.73it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 Loss:38.962, MAE:646.87, MSE:947.36, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:34<00:00,  1.73it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 Loss:38.205, MAE:631.52, MSE:948.47, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:34<00:00,  1.73it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 Loss:35.845, MAE:606.43, MSE:914.40, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:34<00:00,  1.73it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 Loss:34.046, MAE:608.16, MSE:917.59, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:34<00:00,  1.73it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 Loss:33.762, MAE:632.17, MSE:934.16, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:34<00:00,  1.73it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 Loss:35.083, MAE:593.95, MSE:911.02, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:34<00:00,  1.73it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 Loss:31.969, MAE:635.35, MSE:932.61, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:34<00:00,  1.73it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 Loss:31.016, MAE:642.21, MSE:945.73, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:34<00:00,  1.73it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 Loss:30.388, MAE:635.01, MSE:944.69, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:34<00:00,  1.73it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 Loss:30.318, MAE:639.32, MSE:945.09, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:34<00:00,  1.73it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 Loss:30.796, MAE:595.74, MSE:906.37, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:34<00:00,  1.73it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 Loss:29.240, MAE:600.02, MSE:905.92, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:34<00:00,  1.73it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 Loss:28.902, MAE:607.00, MSE:914.27, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:34<00:00,  1.73it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 Loss:27.970, MAE:600.19, MSE:918.93, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:33<00:00,  1.73it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 Loss:26.204, MAE:630.22, MSE:946.41, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:34<00:00,  1.73it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50 Loss:26.733, MAE:628.54, MSE:936.13, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:34<00:00,  1.73it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50 Loss:26.337, MAE:610.90, MSE:928.07, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:34<00:00,  1.73it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50 Loss:25.515, MAE:611.86, MSE:931.01, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:36<00:00,  1.72it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50 Loss:25.791, MAE:624.00, MSE:930.40, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:39<00:00,  1.72it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50 Loss:27.004, MAE:644.14, MSE:954.91, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:38<00:00,  1.72it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50 Loss:24.763, MAE:650.49, MSE:951.37, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:39<00:00,  1.72it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50 Loss:24.585, MAE:628.53, MSE:938.81, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:39<00:00,  1.71it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50 Loss:22.768, MAE:625.97, MSE:938.51, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:37<00:00,  1.72it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50 Loss:23.007, MAE:618.96, MSE:926.71, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:35<00:00,  1.73it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50 Loss:23.696, MAE:615.01, MSE:923.79, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:34<00:00,  1.73it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50 Loss:21.867, MAE:634.47, MSE:947.20, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:34<00:00,  1.73it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50 Loss:22.782, MAE:603.54, MSE:910.42, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:33<00:00,  1.73it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50 Loss:22.731, MAE:619.80, MSE:925.90, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:33<00:00,  1.73it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50 Loss:20.286, MAE:613.99, MSE:929.41, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:33<00:00,  1.73it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50 Loss:21.184, MAE:607.24, MSE:916.88, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:33<00:00,  1.73it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50 Loss:20.714, MAE:613.11, MSE:920.91, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:34<00:00,  1.73it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50 Loss:20.556, MAE:625.47, MSE:934.37, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:34<00:00,  1.73it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50 Loss:21.098, MAE:609.07, MSE:916.75, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:33<00:00,  1.73it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50 Loss:18.699, MAE:603.82, MSE:909.36, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:33<00:00,  1.73it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50 Loss:21.429, MAE:628.10, MSE:934.80, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:33<00:00,  1.73it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50 Loss:20.641, MAE:639.26, MSE:947.56, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:33<00:00,  1.73it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50 Loss:18.082, MAE:607.30, MSE:910.99, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:33<00:00,  1.73it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50 Loss:18.992, MAE:636.80, MSE:955.36, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:33<00:00,  1.73it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50 Loss:18.015, MAE:632.19, MSE:944.60, Best MAE:570.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:34<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 Loss:19.286, MAE:619.90, MSE:929.70, Best MAE:570.82\n",
      "200\n",
      "Report sent\n"
     ]
    }
   ],
   "source": [
    "dsn_net = train_model(dsn_net, train_loader, test_loader, optimizer, MODEL_SAVE_PATH)\n",
    "report_to_overwatch('VM:ML:P', 'Atlas', 'Training of model done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, target, count = next(iter(test_loader))\n",
    "img = img.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = dsn_net(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.05695939064025879"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([332.], dtype=torch.float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.7 Pytorch",
   "language": "python",
   "name": "torchpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

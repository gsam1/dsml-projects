{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Image Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIRAT_S_000002_fr_0.2\n"
     ]
    }
   ],
   "source": [
    "!ls ./example_dataset/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = os.listdir('./example_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_file_extension(filename):\n",
    "    \n",
    "    file_extension = 'mp4'\n",
    "    \n",
    "    if file_extension in filename:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def get_videos_from_folder(path):\n",
    "    \n",
    "    all_items = os.listdir(path)\n",
    "    only_videos = [video_name for video_name in filter(filter_file_extension, all_items)]\n",
    "    video_filenames = [video_name.split('.')[0] for video_name in only_videos]\n",
    "    videos_file_paths = [os.path.join(path, video_fp) for video_fp in only_videos]\n",
    "    \n",
    "    return videos_file_paths, video_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_file_paths, video_filenames = get_videos_from_folder('./example_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame(sec, video_object):\n",
    "    '''\n",
    "        Based on the given sec, extract the resulting image from the video_object.\n",
    "    '''\n",
    "    video_object.set(cv2.CAP_PROP_POS_MSEC, sec*1000)\n",
    "    success, image = video_object.read()\n",
    "    return success, image\n",
    "    \n",
    "\n",
    "def write_images_from_video(video_path, video_filename, frame_rate):\n",
    "    '''\n",
    "        Splits the video by the frame_rate, shown in the video_path variable into different frames,\n",
    "        then writes the resulting images in a folder with the  video's filename.\n",
    "        Creates the folder if it exits.\n",
    "    \n",
    "    '''\n",
    "    video_object = cv2.VideoCapture(video_path)\n",
    "    sec = 0\n",
    "    count = 0\n",
    "    frame_rate = 1 / frame_rate # looking at the actual time from second to the next\n",
    "    success = 1\n",
    "    \n",
    "    while success:\n",
    "        \n",
    "        success, image = get_frame(sec, video_object)\n",
    "        \n",
    "        # create the folder if not exists\n",
    "        video_file_name = f'{video_filename}_fr_{frame_rate}'\n",
    "        folder_path = f'./example_dataset/images/{video_file_name}'\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "        \n",
    "        # write the image\n",
    "        cv2.imwrite(os.path.join(folder_path, f'{video_filename}_frame_{np.round(count,2)}.png'), image)\n",
    "        \n",
    "        sec = sec + frame_rate\n",
    "        count += 1\n",
    "    \n",
    "    print(f'File {video_filename} processed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File VIRAT_S_000002 processed.\n"
     ]
    }
   ],
   "source": [
    "write_images_from_video(video_file_paths[0], video_filenames[0], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/fury/Code/projects/dsml-projects/4_End-to-End_Project/People_Counting_From_Video_Feed/PoC\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## People Counting with Object Recognition Methods\n",
    "\n",
    "[Reference](https://machinelearningmastery.com/object-recognition-with-deep-learning/?fbclid=IwAR3QHzwV3iteB2tE7EJo3GkNTT_v7loLqHtCqYuH5nopySIkzvTmHiUa-H0)\n",
    "\n",
    "### 1. Faster R-CNN\n",
    "* [Reference of Faster R-CNN](https://arxiv.org/pdf/1506.01497.pdf)  \n",
    "* [Reference of implementation](https://towardsdatascience.com/faster-r-cnn-object-detection-implemented-by-keras-for-custom-data-from-googles-open-images-125f62b9141a)\n",
    "* [Reference Jupyter Notebook for the implementation](https://github.com/RockyXu66/Faster_RCNN_for_Open_Images_Dataset_Keras/blob/master/frcnn_train_vgg.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Getting The Data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-11-26 21:53:32--  https://datasets.figure-eight.com/figure_eight_datasets/open-images/train-annotations-bbox.csv\n",
      "Resolving datasets.figure-eight.com (datasets.figure-eight.com)... 52.200.149.96, 3.227.119.162, 3.227.227.96\n",
      "Connecting to datasets.figure-eight.com (datasets.figure-eight.com)|52.200.149.96|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1194033454 (1,1G) [text/csv]\n",
      "Saving to: ‘train-annotations-bbox.csv’\n",
      "\n",
      "tions-bbox.csv       27%[====>               ] 311,04M   537KB/s    eta 51m 27s"
     ]
    }
   ],
   "source": [
    "!wget https://datasets.figure-eight.com/figure_eight_datasets/open-images/train-annotations-bbox.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://datasets.figure-eight.com/figure_eight_datasets/open-images/train-images-boxable.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 OpenCV",
   "language": "python",
   "name": "opencv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TMDB Box Office Prediction\n",
    "\n",
    "The notebook's purpose is to produce submissions for the [Kaggle Competition](https://www.kaggle.com/c/tmdb-box-office-prediction/data).\n",
    "The challenge is to predict the box office of a movie, given a number of factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading and neccessary libraries import\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ast\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './datasets/tmdb-box-office-prediction/'\n",
    "train_location = os.path.join(PATH, 'train.csv')\n",
    "test_location = os.path.join(PATH, 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(train_location)\n",
    "test = pd.read_csv(test_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>...</th>\n",
       "      <th>release_date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>cast</th>\n",
       "      <th>crew</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[{'id': 313576, 'name': 'Hot Tub Time Machine ...</td>\n",
       "      <td>14000000</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt2637294</td>\n",
       "      <td>en</td>\n",
       "      <td>Hot Tub Time Machine 2</td>\n",
       "      <td>When Lou, who has become the \"father of the In...</td>\n",
       "      <td>6.575393</td>\n",
       "      <td>...</td>\n",
       "      <td>2/20/15</td>\n",
       "      <td>93.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>The Laws of Space and Time are About to be Vio...</td>\n",
       "      <td>Hot Tub Time Machine 2</td>\n",
       "      <td>[{'id': 4379, 'name': 'time travel'}, {'id': 9...</td>\n",
       "      <td>[{'cast_id': 4, 'character': 'Lou', 'credit_id...</td>\n",
       "      <td>[{'credit_id': '59ac067c92514107af02c8c8', 'de...</td>\n",
       "      <td>12314651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[{'id': 107674, 'name': 'The Princess Diaries ...</td>\n",
       "      <td>40000000</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt0368933</td>\n",
       "      <td>en</td>\n",
       "      <td>The Princess Diaries 2: Royal Engagement</td>\n",
       "      <td>Mia Thermopolis is now a college graduate and ...</td>\n",
       "      <td>8.248895</td>\n",
       "      <td>...</td>\n",
       "      <td>8/6/04</td>\n",
       "      <td>113.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>It can take a lifetime to find true love; she'...</td>\n",
       "      <td>The Princess Diaries 2: Royal Engagement</td>\n",
       "      <td>[{'id': 2505, 'name': 'coronation'}, {'id': 42...</td>\n",
       "      <td>[{'cast_id': 1, 'character': 'Mia Thermopolis'...</td>\n",
       "      <td>[{'credit_id': '52fe43fe9251416c7502563d', 'de...</td>\n",
       "      <td>95149435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3300000</td>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}]</td>\n",
       "      <td>http://sonyclassics.com/whiplash/</td>\n",
       "      <td>tt2582802</td>\n",
       "      <td>en</td>\n",
       "      <td>Whiplash</td>\n",
       "      <td>Under the direction of a ruthless instructor, ...</td>\n",
       "      <td>64.299990</td>\n",
       "      <td>...</td>\n",
       "      <td>10/10/14</td>\n",
       "      <td>105.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>The road to greatness can take you to the edge.</td>\n",
       "      <td>Whiplash</td>\n",
       "      <td>[{'id': 1416, 'name': 'jazz'}, {'id': 1523, 'n...</td>\n",
       "      <td>[{'cast_id': 5, 'character': 'Andrew Neimann',...</td>\n",
       "      <td>[{'credit_id': '54d5356ec3a3683ba0000039', 'de...</td>\n",
       "      <td>13092000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200000</td>\n",
       "      <td>[{'id': 53, 'name': 'Thriller'}, {'id': 18, 'n...</td>\n",
       "      <td>http://kahaanithefilm.com/</td>\n",
       "      <td>tt1821480</td>\n",
       "      <td>hi</td>\n",
       "      <td>Kahaani</td>\n",
       "      <td>Vidya Bagchi (Vidya Balan) arrives in Kolkata ...</td>\n",
       "      <td>3.174936</td>\n",
       "      <td>...</td>\n",
       "      <td>3/9/12</td>\n",
       "      <td>122.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kahaani</td>\n",
       "      <td>[{'id': 10092, 'name': 'mystery'}, {'id': 1054...</td>\n",
       "      <td>[{'cast_id': 1, 'character': 'Vidya Bagchi', '...</td>\n",
       "      <td>[{'credit_id': '52fe48779251416c9108d6eb', 'de...</td>\n",
       "      <td>16000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 28, 'name': 'Action'}, {'id': 53, 'nam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt1380152</td>\n",
       "      <td>ko</td>\n",
       "      <td>마린보이</td>\n",
       "      <td>Marine Boy is the story of a former national s...</td>\n",
       "      <td>1.148070</td>\n",
       "      <td>...</td>\n",
       "      <td>2/5/09</td>\n",
       "      <td>118.0</td>\n",
       "      <td>[{'iso_639_1': 'ko', 'name': '한국어/조선말'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marine Boy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'cast_id': 3, 'character': 'Chun-soo', 'cred...</td>\n",
       "      <td>[{'credit_id': '52fe464b9251416c75073b43', 'de...</td>\n",
       "      <td>3923970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                              belongs_to_collection    budget  \\\n",
       "0   1  [{'id': 313576, 'name': 'Hot Tub Time Machine ...  14000000   \n",
       "1   2  [{'id': 107674, 'name': 'The Princess Diaries ...  40000000   \n",
       "2   3                                                NaN   3300000   \n",
       "3   4                                                NaN   1200000   \n",
       "4   5                                                NaN         0   \n",
       "\n",
       "                                              genres  \\\n",
       "0                     [{'id': 35, 'name': 'Comedy'}]   \n",
       "1  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n",
       "2                      [{'id': 18, 'name': 'Drama'}]   \n",
       "3  [{'id': 53, 'name': 'Thriller'}, {'id': 18, 'n...   \n",
       "4  [{'id': 28, 'name': 'Action'}, {'id': 53, 'nam...   \n",
       "\n",
       "                            homepage    imdb_id original_language  \\\n",
       "0                                NaN  tt2637294                en   \n",
       "1                                NaN  tt0368933                en   \n",
       "2  http://sonyclassics.com/whiplash/  tt2582802                en   \n",
       "3         http://kahaanithefilm.com/  tt1821480                hi   \n",
       "4                                NaN  tt1380152                ko   \n",
       "\n",
       "                             original_title  \\\n",
       "0                    Hot Tub Time Machine 2   \n",
       "1  The Princess Diaries 2: Royal Engagement   \n",
       "2                                  Whiplash   \n",
       "3                                   Kahaani   \n",
       "4                                      마린보이   \n",
       "\n",
       "                                            overview  popularity    ...     \\\n",
       "0  When Lou, who has become the \"father of the In...    6.575393    ...      \n",
       "1  Mia Thermopolis is now a college graduate and ...    8.248895    ...      \n",
       "2  Under the direction of a ruthless instructor, ...   64.299990    ...      \n",
       "3  Vidya Bagchi (Vidya Balan) arrives in Kolkata ...    3.174936    ...      \n",
       "4  Marine Boy is the story of a former national s...    1.148070    ...      \n",
       "\n",
       "  release_date runtime                                   spoken_languages  \\\n",
       "0      2/20/15    93.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "1       8/6/04   113.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "2     10/10/14   105.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "3       3/9/12   122.0  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...   \n",
       "4       2/5/09   118.0           [{'iso_639_1': 'ko', 'name': '한국어/조선말'}]   \n",
       "\n",
       "     status                                            tagline  \\\n",
       "0  Released  The Laws of Space and Time are About to be Vio...   \n",
       "1  Released  It can take a lifetime to find true love; she'...   \n",
       "2  Released    The road to greatness can take you to the edge.   \n",
       "3  Released                                                NaN   \n",
       "4  Released                                                NaN   \n",
       "\n",
       "                                      title  \\\n",
       "0                    Hot Tub Time Machine 2   \n",
       "1  The Princess Diaries 2: Royal Engagement   \n",
       "2                                  Whiplash   \n",
       "3                                   Kahaani   \n",
       "4                                Marine Boy   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  [{'id': 4379, 'name': 'time travel'}, {'id': 9...   \n",
       "1  [{'id': 2505, 'name': 'coronation'}, {'id': 42...   \n",
       "2  [{'id': 1416, 'name': 'jazz'}, {'id': 1523, 'n...   \n",
       "3  [{'id': 10092, 'name': 'mystery'}, {'id': 1054...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                                cast  \\\n",
       "0  [{'cast_id': 4, 'character': 'Lou', 'credit_id...   \n",
       "1  [{'cast_id': 1, 'character': 'Mia Thermopolis'...   \n",
       "2  [{'cast_id': 5, 'character': 'Andrew Neimann',...   \n",
       "3  [{'cast_id': 1, 'character': 'Vidya Bagchi', '...   \n",
       "4  [{'cast_id': 3, 'character': 'Chun-soo', 'cred...   \n",
       "\n",
       "                                                crew   revenue  \n",
       "0  [{'credit_id': '59ac067c92514107af02c8c8', 'de...  12314651  \n",
       "1  [{'credit_id': '52fe43fe9251416c7502563d', 'de...  95149435  \n",
       "2  [{'credit_id': '54d5356ec3a3683ba0000039', 'de...  13092000  \n",
       "3  [{'credit_id': '52fe48779251416c9108d6eb', 'de...  16000000  \n",
       "4  [{'credit_id': '52fe464b9251416c75073b43', 'de...   3923970  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 23 columns):\n",
      "id                       3000 non-null int64\n",
      "belongs_to_collection    604 non-null object\n",
      "budget                   3000 non-null int64\n",
      "genres                   2993 non-null object\n",
      "homepage                 946 non-null object\n",
      "imdb_id                  3000 non-null object\n",
      "original_language        3000 non-null object\n",
      "original_title           3000 non-null object\n",
      "overview                 2992 non-null object\n",
      "popularity               3000 non-null float64\n",
      "poster_path              2999 non-null object\n",
      "production_companies     2844 non-null object\n",
      "production_countries     2945 non-null object\n",
      "release_date             3000 non-null object\n",
      "runtime                  2998 non-null float64\n",
      "spoken_languages         2980 non-null object\n",
      "status                   3000 non-null object\n",
      "tagline                  2403 non-null object\n",
      "title                    3000 non-null object\n",
      "Keywords                 2724 non-null object\n",
      "cast                     2987 non-null object\n",
      "crew                     2984 non-null object\n",
      "revenue                  3000 non-null int64\n",
      "dtypes: float64(2), int64(3), object(18)\n",
      "memory usage: 539.1+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -- Plan of Attack\n",
    "1. Clean the dataset, which includes a train and the test set.\n",
    "2. Figure out which features correlate with the revenue.\n",
    "3. Derive new features - this can occur at other times as well.\n",
    "4. Evaluate and choose the best performing model.\n",
    "5. Optimize the chosen model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cleaning Missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3000, 23), (4398, 22))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Dealing with the missing data.\n",
    "#### Wokring with the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missing_by_columns(df):\n",
    "    '''\n",
    "        Prints the columns with missing data and what percentage are they.\n",
    "    '''\n",
    "    total_missing = 0\n",
    "    missing_cols = []\n",
    "    for column in list(df.columns):\n",
    "        missing = df[df[column].isnull()].shape[0]\n",
    "        if missing > 0:\n",
    "            missing_perc = missing / df.shape[0] * 100\n",
    "            print(f'{column} has {np.round(missing_perc, 2)} % missing. Count missing: {missing}')\n",
    "            total_missing += missing\n",
    "            missing_cols.append(column)\n",
    "    \n",
    "    return total_missing, missing_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "belongs_to_collection has 79.87 % missing. Count missing: 2396\n",
      "genres has 0.23 % missing. Count missing: 7\n",
      "homepage has 68.47 % missing. Count missing: 2054\n",
      "overview has 0.27 % missing. Count missing: 8\n",
      "poster_path has 0.03 % missing. Count missing: 1\n",
      "production_companies has 5.2 % missing. Count missing: 156\n",
      "production_countries has 1.83 % missing. Count missing: 55\n",
      "runtime has 0.07 % missing. Count missing: 2\n",
      "spoken_languages has 0.67 % missing. Count missing: 20\n",
      "tagline has 19.9 % missing. Count missing: 597\n",
      "Keywords has 9.2 % missing. Count missing: 276\n",
      "cast has 0.43 % missing. Count missing: 13\n",
      "crew has 0.53 % missing. Count missing: 16\n"
     ]
    }
   ],
   "source": [
    "_, mis_col_list_train = get_missing_by_columns(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_has_a_homepage(df):\n",
    "    ''' Add a has_a_homepage feature to the dataframe.'''\n",
    "    df['has_a_homepage'] = 0\n",
    "    df.loc[~df['homepage'].isnull(),'has_a_homepage'] = 1\n",
    "    df = df.drop(['homepage'], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_part_of_collection(df):\n",
    "    ''' Add a part of collection feature to the dataframe.'''\n",
    "    df['part_of_collection'] = 0\n",
    "    df.loc[~df['belongs_to_collection'].isnull(), 'part_of_collection'] = 1\n",
    "    df = df.drop(['belongs_to_collection'], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_has_a_tagline(df):\n",
    "    ''' Add has_a_tagline feature to the dataframe'''\n",
    "    df['has_a_tagline'] = 0\n",
    "    df.loc[~df['tagline'].isnull(), 'has_a_tagline'] = 1\n",
    "    df = df.drop(['tagline'], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train.copy()\n",
    "test_df = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "train_df = add_has_a_homepage(train_df)\n",
    "train_df = add_part_of_collection(train_df)\n",
    "train_df = add_has_a_tagline(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genres has 0.23 % missing. Count missing: 7\n",
      "overview has 0.27 % missing. Count missing: 8\n",
      "poster_path has 0.03 % missing. Count missing: 1\n",
      "production_companies has 5.2 % missing. Count missing: 156\n",
      "production_countries has 1.83 % missing. Count missing: 55\n",
      "runtime has 0.07 % missing. Count missing: 2\n",
      "spoken_languages has 0.67 % missing. Count missing: 20\n",
      "Keywords has 9.2 % missing. Count missing: 276\n",
      "cast has 0.43 % missing. Count missing: 13\n",
      "crew has 0.53 % missing. Count missing: 16\n",
      "Total Missing: 554\n"
     ]
    }
   ],
   "source": [
    "total_missing, mis_col_list_train = get_missing_by_columns(train_df)\n",
    "print(f'Total Missing: {total_missing}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chances are a lot of those overlap, so lets drop the rows that have 'Keywords' missing and see what we got from there.\n",
    "\n",
    "Handling the missing by column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_sans_miss = train_df[~train_df['Keywords'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genres has 0.07 % missing. Count missing: 2\n",
      "overview has 0.15 % missing. Count missing: 4\n",
      "poster_path has 0.04 % missing. Count missing: 1\n",
      "production_companies has 3.27 % missing. Count missing: 89\n",
      "production_countries has 0.88 % missing. Count missing: 24\n",
      "runtime has 0.04 % missing. Count missing: 1\n",
      "spoken_languages has 0.29 % missing. Count missing: 8\n",
      "cast has 0.48 % missing. Count missing: 13\n",
      "crew has 0.51 % missing. Count missing: 14\n",
      "Total Missing: 156\n"
     ]
    }
   ],
   "source": [
    "total_missing = get_missing_by_columns(train_df_sans_miss)\n",
    "print(f'Total Missing: {total_missing}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well 398 values cleared. Lets put everything in one function and clear them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_missing(columns_with_missing_data, data):\n",
    "    df = data.copy()\n",
    "    for col in columns_with_missing_data:\n",
    "        if df[df[col].isnull()].shape[0] > 0:\n",
    "            df = df[~df[col].isnull()]\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genres\n",
      "overview\n",
      "poster_path\n",
      "production_companies\n",
      "production_countries\n",
      "runtime\n",
      "spoken_languages\n",
      "Keywords\n",
      "cast\n",
      "crew\n"
     ]
    }
   ],
   "source": [
    "train_clean = drop_missing(mis_col_list_train, train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Missing: (0, [])\n"
     ]
    }
   ],
   "source": [
    "total_missing = get_missing_by_columns(train_clean)\n",
    "print(f'Total Missing: {total_missing}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of missing values: 394, Perc: 0.13\n"
     ]
    }
   ],
   "source": [
    "total_lost = train_df.shape[0] - train_clean.shape[0]\n",
    "print(f'Count of missing values: {total_lost}, Perc: {np.round(total_lost / train_df.shape[0], 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A total of 394 values were cleared from the original data set or 13% better than the original 18%. We will use it as a threshold for the test set - If the total missing are more than 15% of the whole dataset - we try to figure it out - otherwise just drop it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with the test set.\n",
    "Let's do an initial check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "belongs_to_collection has 80.06 % missing. Count missing: 3521\n",
      "genres has 0.36 % missing. Count missing: 16\n",
      "homepage has 67.71 % missing. Count missing: 2978\n",
      "overview has 0.32 % missing. Count missing: 14\n",
      "poster_path has 0.02 % missing. Count missing: 1\n",
      "production_companies has 5.87 % missing. Count missing: 258\n",
      "production_countries has 2.32 % missing. Count missing: 102\n",
      "release_date has 0.02 % missing. Count missing: 1\n",
      "runtime has 0.09 % missing. Count missing: 4\n",
      "spoken_languages has 0.95 % missing. Count missing: 42\n",
      "status has 0.05 % missing. Count missing: 2\n",
      "tagline has 19.62 % missing. Count missing: 863\n",
      "title has 0.07 % missing. Count missing: 3\n",
      "Keywords has 8.94 % missing. Count missing: 393\n",
      "cast has 0.3 % missing. Count missing: 13\n",
      "crew has 0.5 % missing. Count missing: 22\n"
     ]
    }
   ],
   "source": [
    "_, mis_col_list_test = get_missing_by_columns(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(df):\n",
    "    df_clean = df.copy()\n",
    "    df_clean = add_has_a_homepage(df_clean)\n",
    "    df_clean = add_part_of_collection(df_clean)\n",
    "    df_clean = add_has_a_tagline(df_clean)\n",
    "    \n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = add_features(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial features have been added - let's check for the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genres has 0.36 % missing. Count missing: 16\n",
      "overview has 0.32 % missing. Count missing: 14\n",
      "poster_path has 0.02 % missing. Count missing: 1\n",
      "production_companies has 5.87 % missing. Count missing: 258\n",
      "production_countries has 2.32 % missing. Count missing: 102\n",
      "release_date has 0.02 % missing. Count missing: 1\n",
      "runtime has 0.09 % missing. Count missing: 4\n",
      "spoken_languages has 0.95 % missing. Count missing: 42\n",
      "status has 0.05 % missing. Count missing: 2\n",
      "title has 0.07 % missing. Count missing: 3\n",
      "Keywords has 8.94 % missing. Count missing: 393\n",
      "cast has 0.3 % missing. Count missing: 13\n",
      "crew has 0.5 % missing. Count missing: 22\n",
      "Total Missing: 871\n"
     ]
    }
   ],
   "source": [
    "total_missing, missing_cols_test = get_missing_by_columns(test_df)\n",
    "print(f'Total Missing: {total_missing}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20% of the data is missing... Lets drop the rows with these values missing and see the total loss of samples. As I said earlier 15% is the threshold I am willing to tolerate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clean = drop_missing(missing_cols_test, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of missing values: 584, Perc: 0.13\n"
     ]
    }
   ],
   "source": [
    "total_lost = test_df.shape[0] - test_clean.shape[0]\n",
    "print(f'Count of missing values cleaned: {total_lost}, Perc: {np.round(total_lost / test_df.shape[0], 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again 13% - we can tolerate that. In a later revision we can try to fill some of the values..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. EDA\n",
    "\n",
    "Let's try to find the hidden features in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*A litte side track.*  \n",
    "Let's get the unique genres in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_genre_list(df):\n",
    "    # construct the list of genres\n",
    "    genres_col = df['genres']\n",
    "    genres_list = []\n",
    "    for item in genres_col:\n",
    "        if str(item) == 'nan':\n",
    "            pass\n",
    "        else:\n",
    "            genres_list +=  ast.literal_eval(item)\n",
    "    \n",
    "    # construct the lists for both ids and genres\n",
    "    genre_string_list = []\n",
    "    genre_id_list = []\n",
    "    for movie in genres_list:\n",
    "        genre_string_list.append(movie['name'])\n",
    "        genre_id_list.append(movie['id'])\n",
    "    # filter for unique\n",
    "    unique_ids = []\n",
    "    unique_genres = []\n",
    "    for i in range(0, len(genre_id_list)):\n",
    "        if genre_id_list[i] not in unique_ids:\n",
    "            unique_ids.append(genre_id_list[i])\n",
    "            unique_genres.append(genre_string_list[i])\n",
    "            \n",
    "    return {\n",
    "        'genre_strings': unique_genres,\n",
    "        'genre_id': unique_ids\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_list = get_genre_list(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[35,\n",
       " 18,\n",
       " 10751,\n",
       " 10749,\n",
       " 53,\n",
       " 28,\n",
       " 16,\n",
       " 12,\n",
       " 27,\n",
       " 99,\n",
       " 10402,\n",
       " 80,\n",
       " 878,\n",
       " 9648,\n",
       " 10769,\n",
       " 14,\n",
       " 10752,\n",
       " 37,\n",
       " 36,\n",
       " 10770]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_list['genre_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
